# -*- coding: utf-8 -*-
"""ml_hotel_booking_prediction_shan_singh.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RcAawGn3VpeP2y8TRw8StPmQx1qxbSJE
"""





""" # 1.. lets read data.."""



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv(r'F:/Data_science_projects/Hotel_booking/hotel_bookings.csv')

type(df)

df.head(3)





"""# 2.. lets perform data cleaning.."""

df.shape



df.isnull().sum()

df.drop(['agent','company'],axis=1,inplace=True)



df['country'].value_counts().index[0]

df['country'].fillna(df['country'].value_counts().index[0],inplace=True)

df.fillna(0,inplace=True)

df.isnull().sum()

### seems to have some dirtiness in data as Adults,babies & children cant be zero at a same time ..

### bcz if 3 entities are 0 ,then how can a booking be possible ??

### Visualise Entire Dataframe where adult,children & babies are 0

filter1=(df['children']==0) & (df['adults']==0) & (df['babies']==0)

df[filter1]

data=df[~filter1]

data.shape

df.shape



df[df['children']==0]







"""# 3.. Where do the guests come from ?"""

## Lets perform Spatial Analysis

data['is_canceled'].unique()

data[data['is_canceled']==0]['country'].value_counts()/75011

len(data[data['is_canceled']==0])

country_wise_data=data[data['is_canceled']==0]['country'].value_counts().reset_index()
country_wise_data.columns=['country','no_of_guests']
country_wise_data

##!pip install plotly

##!pip install chart_studio

import plotly
import chart_studio.plotly as py
from plotly.offline import download_plotlyjs ,init_notebook_mode ,plot ,iplot
init_notebook_mode(connected=True)

import plotly.express as px

map_guest=px.choropleth(country_wise_data,
             locations=country_wise_data['country'],
             color=country_wise_data['no_of_guests'],
              hover_name=country_wise_data['country'],
              title='home country of guests'
             )

map_guest.show()

"""Conclusion : People from all over the world are staying in these two hotels. Most guests are from Portugal and other countries in Europe"""







"""# 4.. How much do guests pay for a room per night ?

Both hotels have different room types and different meal arrangements. Seasonal factors are also important. So the prices vary a lot. Since no currency information is given, but Portugal is part of the European Monetary Union, I assume that all prices are in EUR.
"""

data2=data[data['is_canceled']==0]

data2.columns

# seaborn boxplot:

plt.figure(figsize=(12,8))
sns.boxplot(x='reserved_room_type',y='adr' ,hue='hotel',data=data2)

plt.title('Price of room types per night and person')
plt.xlabel('room types')
plt.ylabel('price( EUR)')

"""This figure shows the average price per room, depending on its type and the standard deviation. Note that due to data anonymization rooms with the same type letter may not necessarily be the same across hotels."""









"""# 5.. Which are the most busy month ?"""

data['hotel'].unique()

data_resort=data[(data['hotel']=='Resort Hotel') & (data['is_canceled']==0)]
data_city = data[(data['hotel']=='City Hotel') & (data['is_canceled']==0)]

data_resort.head(3)

rush_resort=data_resort['arrival_date_month'].value_counts().reset_index()
rush_resort.columns=['month','no_of_guests']
rush_resort

rush_city=data_city['arrival_date_month'].value_counts().reset_index()
rush_city.columns=['month','no_of_guests']
rush_city

final_rush=rush_resort.merge(rush_city,on='month')

final_rush.columns=['month','no_of_guests_in_resort','no_of_guests_city']

final_rush

"""now we will observe over here is month column is not in order, & if we will visualise we will get improper conclusion
so very first we have to provide right hierarchy to the month column
"""



!pip install sorted-months-weekdays

## Dependency package needs to be installed
!pip install sort_dataframeby_monthorweek

import sort_dataframeby_monthorweek as sd

final_rush=sd.Sort_Dataframeby_Month(final_rush,'month')

final_rush.columns

px.line(data_frame=final_rush,x='month',y=['no_of_guests_in_resort', 'no_of_guests_city'])

"""Conclusion-->> This clearly shows that the prices in the Resort hotel are much higher during the summer (no surprise here)., The price of the city hotel varies less and is most expensive during spring and autumn."""









"""# 6.. which month has highest adr ?"""

data=sd.Sort_Dataframeby_Month(data,'arrival_date_month')

sns.barplot(x='arrival_date_month',y='adr',data=data ,hue='is_canceled')
plt.xticks(rotation='vertical')
plt.show()

plt.figure(figsize=(12,8))
sns.boxplot(x='arrival_date_month',y='adr',data=data ,hue='is_canceled')
plt.xticks(rotation='vertical')


plt.ylim(0,800)
plt.show()









"""# 7.. Lets analyse whether bookings were made only for weekdays or for weekends or for both ??"""

data.columns



### Lets create a relationship table..
pd.crosstab(index=data['stays_in_weekend_nights'],columns=data['stays_in_week_nights'])



## lets define our own function :

def week_function(row):
    feature1='stays_in_weekend_nights'
    feature2='stays_in_week_nights'

    if row[feature2]==0 and row[feature1] >0 :
        return 'stay_just_weekend'

    elif row[feature2]>0 and row[feature1] ==0 :
        return 'stay_just_weekdays'

    elif row[feature2]>0 and row[feature1] >0 :
        return 'stay_both_weekdays_weekends'

    else:
        return 'undefined_data'

data2['weekend_or_weekday']=data2.apply(week_function,axis=1)

data2.head(2)

data2['weekend_or_weekday'].value_counts()

type(sd)

data2=sd.Sort_Dataframeby_Month(data2,'arrival_date_month')

data2.groupby(['arrival_date_month','weekend_or_weekday']).size()

group_data=data2.groupby(['arrival_date_month','weekend_or_weekday']).size().unstack().reset_index()

sorted_data=sd.Sort_Dataframeby_Month(group_data,'arrival_date_month')

sorted_data.set_index('arrival_date_month',inplace=True)

sorted_data

sorted_data.plot(kind='bar',stacked=True,figsize=(15,10))









"""# 8.. How to create some more features .."""

data2.columns



def family(row):
    if (row['adults']>0) &  (row['children']>0 or row['babies']>0) :
        return 1
    else:
        return 0

data['is_family']=data.apply(family,axis=1)

data['total_customer'] = data['adults'] + data['babies'] + data['children']

data['total_nights']=data['stays_in_week_nights'] + data['stays_in_weekend_nights']

data.head(3)

data.columns

data['deposit_type'].unique()

dict1={'No Deposit':0, 'Non Refund':1, 'Refundable': 0}

data['deposit_given']=data['deposit_type'].map(dict1)

data.columns

data.drop(columns=['adults', 'children', 'babies', 'deposit_type'],axis=1,inplace=True)

data.columns









"""# 9.. how to apply Feature encoding on data"""

data.head(6)

data.dtypes

data.columns

cate_features=[col for col in data.columns if data[col].dtype=='object']

num_features=[col for col in data.columns if data[col].dtype!='object']

num_features

cate_features

data_cat=data[cate_features]





data.groupby(['hotel'])['is_canceled'].mean().to_dict()

import warnings
from warnings import filterwarnings
filterwarnings('ignore')

data_cat['cancellation']=data['is_canceled']

data_cat.head()

cols=data_cat.columns

cols=cols[0:-1]

cols

### Perform Mean Encoding Technique

for col in cols:
    dict2=data_cat.groupby([col])['cancellation'].mean().to_dict()
    data_cat[col]=data_cat[col].map(dict2)

data_cat.head(3)









"""# 10.. Handle Outliers"""

data[num_features]



dataframe=pd.concat([data_cat,data[num_features]],axis=1)

dataframe.columns

dataframe.drop(['cancellation'],axis=1,inplace=True)

dataframe.head(3)



sns.distplot(dataframe['lead_time'])



def handle_outlier(col):
    dataframe[col]=np.log1p(dataframe[col])

handle_outlier('lead_time')

sns.distplot(dataframe['lead_time'])



## adr

sns.distplot(dataframe['adr'])

dataframe[dataframe['adr']<0]

handle_outlier('adr')

dataframe['adr'].isnull().sum()

### now why this missing value , as we have already deal with the missing values..'
### bcz we have negative value in 'adr' feature as '-6.38'  ,& if we apply ln(1+x) , we will get 'nan'
## bcz log wont take negative values..

sns.distplot(dataframe['adr'].dropna())







"""# 11.. Select important Features using Co-relation & univariate analysis.."""

sns.FacetGrid(data,hue='is_canceled',xlim=(0,500)).map(sns.kdeplot,'lead_time',shade=True).add_legend()

corr=dataframe.corr()

corr

corr['is_canceled'].sort_values(ascending=False)

corr['is_canceled'].sort_values(ascending=False).index

features_to_drop=['reservation_status', 'reservation_status_date','arrival_date_year',
       'arrival_date_week_number', 'stays_in_weekend_nights',
       'arrival_date_day_of_month']

dataframe.drop(features_to_drop,axis=1,inplace=True)

dataframe.shape







"""# 12.. How to find Important features for model building.."""

dataframe.head(2)

dataframe.isnull().sum()

dataframe.dropna(inplace=True)



## separate dependent & independent features

x=dataframe.drop('is_canceled',axis=1)

y=dataframe['is_canceled']

from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectFromModel

##Lasso(alpha=0.005)
# select a suitable alpha (equivalent of penalty).
# The bigger the alpha the less features that will be selected.

feature_sel_model=SelectFromModel(Lasso(alpha=0.005))

feature_sel_model.fit(x,y)

feature_sel_model.get_support()

cols=x.columns

cols

# let's print the number of selected features

selected_feature=cols[feature_sel_model.get_support()]

selected_feature

x=x[selected_feature]

y









"""# 13.. Lets build ML model.."""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.25)

X_train.shape

from sklearn.linear_model import LogisticRegression

logreg=LogisticRegression()

logreg.fit(X_train,y_train)

pred=logreg.predict(X_test)

pred

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test,pred)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,pred)







"""# 14.. How to cross-validate model.."""

from sklearn.model_selection import cross_val_score

score=cross_val_score(logreg,x,y,cv=10)

score

score.mean()









"""# 15.. playing with multiple algos.."""

from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

from

models=[]

models.append(('LogisticRegression',LogisticRegression()))
models.append(('Naive_bayes',GaussianNB()))
models.append(('Random Forest',RandomForestClassifier()))
models.append(('Decision_tree',DecisionTreeClassifier()))
models.append(('KNN',KNeighborsClassifier()))

for name,model in models:
    print(name)
    model.fit(X_train,y_train)

    predictions=model.predict(X_test)

    from sklearn.metrics import confusion_matrix
    cm=confusion_matrix(predictions,y_test)
    print(cm)

    from sklearn.metrics import accuracy_score
    acc=accuracy_score(predictions,y_test)
    print(acc)
    print('\n')







